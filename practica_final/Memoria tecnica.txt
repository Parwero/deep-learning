MEMORIA DE PRÁCTICA - DEEP LEARNING
CHRISTIAN FELIPE GUEVARA ALBARRACIN

La actualice despues de la entrega porque no me dio tiempo a hacer algo decente, perdona 

1. INTRODUCCIÓN
Hola Luis. En esta práctica, mi objetivo ha sido crear una Inteligencia Artificial capaz de predecir si un punto turístico de Madrid va a tener éxito ("Engagement") o no.
Para ello, no me servía solo con mirar la foto del sitio, así que he intentado hacer un "modelo híbrido": una red que mira la imagen y a la vez lee los datos del Excel (ubicación, categoría, etc.).

He seguido estos pasos:
1. Cargar los datos (que me dio bastante guerra).
2. Inventarme una métrica de éxito (porque no venía hecha).
3. Montar la arquitectura de la red.
4. Entrenar y pelearme con los fallos.
5. Ver qué tal ha salido.

2. PREPARACIÓN DE LOS DATOS
La parte de ingeniería de datos fue lo primero que me atascó.
- El Drive: Al principio intentaba subir los archivos a mano, pero eran demasiados. Al final conseguí montar el Google Drive y tuve que pelearme con las rutas usando `os.path.join` para que el código encontrara la foto exacta de cada ID.
- La variable "Score": Como el dataset no me decía "este sitio es bueno", creé yo la variable `raw_score` sumando likes, bookmarks y visitas (y restando dislikes).
- La Clasificación: Al ver los datos, vi que había muchísimos sitios con 0 visitas. Si usaba la media, casi nadie aprobaba. Así que dividí los datos "a mano" en Bajo, Medio y Alto para que tuviera más sentido.

Un detalle técnico: Para separar los datos de validación (15%) del trozo que me quedaba (85%), tuve que hacer una regla de tres en el código (test_size=0.1765).

4. Modelo
Para que esto funcionara, tuve que tomar varias decisiones técnicas basándome en los notebooks de clase:

No podía usar la herramienta estándar de PyTorch porque necesitaba cargar imagen + números a la vez.
Lo más importante que hice aquí fue un bloque de seguridad (try-except): si una imagen está rota o no existe, mi código genera una imagen negra vacía y sigue entrenando. Prefería eso a que se me parara el entrenamiento a mitad.
Cosa que me ocurrio al princio y no sabia porque. 
He usado una ResNet18 preentrenada.
Por ultimo Una capa lineal final que decide entre las 3 clases.

4. ENTRENAMIENTO 
En las primeras pruebas, como había muchos sitios "Bajos" (Clase 0), la red aprendió a decir siempre "Bajo" y acertaba bastante sin esforzarse.
- Solución: Calculé unos pesos para obligar a la red a prestar más atención a las clases difíciles. Le puse el doble de peso a la Clase Media (que es la que menos datos tiene).

También apliqué Data Augmentation pero solo en el entrenamiento, para que no memorizara las imágenes exactas.

Después de entrenar 15 épocas, he sacado el reporte final.
La Accuracy global es del 45%. Sé que parece baja, pero analizando los detalles:

- Lo Bueno (Clase Alta): El modelo tiene un Recall del 70%. O sea, es capaz de detectar 7 de cada 10 sitios exitosos. Pilla bien los patrones de lo que es un sitio "Top".
- Lo Malo (Clase Media): Aquí ha fallado (Recall 0.02). Básicamente, ignora los sitios "normales". Supongo que un sitio "regular" no tiene características visuales muy claras.

CONCLUSIÓN FINAL:
Aunque la nota numérica (45%) no sea espectacular, creo que he conseguido que funcione un modelo híbrido, he solucionado los errores de carga y he aplicado transfer learning. Para mejorar esto, creo que necesitaría muchos más datos. 